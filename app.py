
import streamlit as st
import pandas as pd
from io import BytesIO
from datetime import datetime

st.set_page_config(page_title="ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï")

st.sidebar.markdown("### âš–ï¸ ÎŒÏÎ¿Î¹ Ï‡ÏÎ®ÏƒÎ·Ï‚")
terms_ok = st.sidebar.checkbox("Î‘Ï€Î¿Î´Î­Ï‡Î¿Î¼Î±Î¹ Ï„Î¿Ï…Ï‚ ÏŒÏÎ¿Ï…Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚", value=False)
st.sidebar.markdown("Â© 2025 â€¢ Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± â€¢ All rights reserved")

if not terms_ok:
    st.warning("âš ï¸ Î“Î¹Î± Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®, Î±Ï€Î¿Î´Î­Î¾Î¿Ï… Ï„Î¿Ï…Ï‚ ÏŒÏÎ¿Ï…Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚ (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬).")
    st.stop()

# Session State
for key, default in [("data", None), ("stats_df", None), ("show_upload", False), ("diagnostics", {})]:
    if key not in st.session_state:
        st.session_state[key] = default

# ---------- Column normalization ----------
# Canonical keys: remove spaces/underscores and uppercase
def canon(s: str) -> str:
    return "".join((s or "").replace("_"," ").split()).upper()

CANON_TARGETS = {
    "ÎŸÎÎŸÎœÎ‘": {"ÎŸÎÎŸÎœÎ‘"},
    "Î¦Î¥Î›ÎŸ": {"Î¦Î¥Î›ÎŸ"},
    "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥": {"Î Î‘Î™Î”Î™Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥", "Î Î‘Î™Î”Î™-Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥"},
    "Î–Î©Î—Î¡ÎŸÎ£": {"Î–Î©Î—Î¡ÎŸÎ£"},
    "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘": {"Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘"},
    "ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î": {"ÎšÎ‘Î›Î—Î“ÎÎ©Î£Î—Î•Î›Î›Î—ÎÎ™ÎšÎ©Î", "Î“ÎÎ©Î£Î—Î•Î›Î›Î—ÎÎ™ÎšÎ©Î"},
    "Î¦Î™Î›ÎŸÎ™": {"Î¦Î™Î›ÎŸÎ™", "Î¦Î™Î›Î™Î‘"},
    "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—": {"Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—", "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£"},
    "Î¤ÎœÎ—ÎœÎ‘": {"Î¤ÎœÎ—ÎœÎ‘"},
}

REQUIRED_COLS = ["ÎŸÎÎŸÎœÎ‘","Î¦Î¥Î›ÎŸ","Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","Î–Î©Î—Î¡ÎŸÎ£","Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","Î¦Î™Î›ÎŸÎ™","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—","Î¤ÎœÎ—ÎœÎ‘"]

def auto_rename_columns(df: pd.DataFrame):
    mapping = {}
    seen = set()
    for col in df.columns:
        c = canon(col)
        found_target = None
        for target, keys in CANON_TARGETS.items():
            if c in keys and target not in seen:
                found_target = target
                seen.add(target)
                break
        if found_target:
            mapping[col] = found_target
    return df.rename(columns=mapping), mapping

def _normalize_yes_no(series: pd.Series) -> pd.Series:
    if series.dtype == object:
        s = series.fillna("").astype(str).str.strip().str.upper()
        s = s.replace({
            "ÎÎ‘Î™":"Î","NAI":"Î","YES":"Î","Y":"Î",
            "ÎŸÎ§Î™":"ÎŸ","OXI":"ÎŸ","NO":"ÎŸ","N":"ÎŸ","": "ÎŸ"
        })
        return s.where(s.isin(["Î","ÎŸ"]), other="ÎŸ")
    return series

def _broken_mutual_friendships_per_class(df: pd.DataFrame) -> pd.Series:
    # Accept Î¦Î™Î›ÎŸÎ™ (already normalized)
    fcol = "Î¦Î™Î›ÎŸÎ™" if "Î¦Î™Î›ÎŸÎ™" in df.columns else None
    if fcol is None or "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
        return df.groupby("Î¤ÎœÎ—ÎœÎ‘").size() * 0

    def norm_name(x: str) -> str:
        return (x or "").strip()

    names = df["ÎŸÎÎŸÎœÎ‘"].fillna("").astype(str).apply(norm_name)
    class_by_name = dict(zip(names, df["Î¤ÎœÎ—ÎœÎ‘"]))

    friends_map = {}
    for _, row in df.iterrows():
        me = norm_name(str(row.get("ÎŸÎÎŸÎœÎ‘", "")))
        raw = str(row.get(fcol, "") or "")
        flist = [norm_name(p) for p in raw.split(",") if norm_name(p)]
        friends_map[me] = set(flist)

    mutual_pairs = set()
    for a, flist in friends_map.items():
        for b in flist:
            if b in friends_map and a in friends_map[b]:
                mutual_pairs.add(tuple(sorted([a,b])))

    broken_count_by_class = {tmima: 0 for tmima in df["Î¤ÎœÎ—ÎœÎ‘"].dropna().unique()}
    for a, b in mutual_pairs:
        ta = class_by_name.get(a)
        tb = class_by_name.get(b)
        if ta and tb and ta != tb:
            broken_count_by_class[ta] = broken_count_by_class.get(ta, 0) + 1
            broken_count_by_class[tb] = broken_count_by_class.get(tb, 0) + 1

    return pd.Series(broken_count_by_class)

def _generate_stats(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    # Normalize core fields
    if "Î¦Î¥Î›ÎŸ" in df:
        df["Î¦Î¥Î›ÎŸ"] = df["Î¦Î¥Î›ÎŸ"].fillna("").astype(str).str.strip().str.upper()
    for col in ["Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","Î–Î©Î—Î¡ÎŸÎ£","Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î"]:
        if col in df:
            df[col] = _normalize_yes_no(df[col])

    boys = df[df["Î¦Î¥Î›ÎŸ"] == "Î‘"].groupby("Î¤ÎœÎ—ÎœÎ‘").size()
    girls = df[df["Î¦Î¥Î›ÎŸ"] == "Îš"].groupby("Î¤ÎœÎ—ÎœÎ‘").size()
    educators = df[df["Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥"] == "Î"].groupby("Î¤ÎœÎ—ÎœÎ‘").size()
    energetic = df[df["Î–Î©Î—Î¡ÎŸÎ£"] == "Î"].groupby("Î¤ÎœÎ—ÎœÎ‘").size()
    special = df[df["Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘"] == "Î"].groupby("Î¤ÎœÎ—ÎœÎ‘").size()
    greek = df[df["ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î"] == "Î"].groupby("Î¤ÎœÎ—ÎœÎ‘").size()
    total = df.groupby("Î¤ÎœÎ—ÎœÎ‘").size()

    broken_by_class = _broken_mutual_friendships_per_class(df)

    stats = pd.DataFrame({
        "Î‘Î“ÎŸÎ¡Î™Î‘": boys,
        "ÎšÎŸÎ¡Î™Î¤Î£Î™Î‘": girls,
        "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥": educators,
        "Î–Î©Î—Î¡ÎŸÎ™": energetic,
        "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘": special,
        "Î“ÎÎ©Î£Î— Î•Î›Î›Î—ÎÎ™ÎšÎ©Î": greek,
        "Î£Î Î‘Î£ÎœÎ•ÎÎ— Î¦Î™Î›Î™Î‘": broken_by_class,
        "Î£Î¥ÎÎŸÎ›ÎŸ": total,
    }).fillna(0).astype(int)

    try:
        stats = stats.sort_index(key=lambda x: x.str.extract(r"(\d+)")[0].astype(float))
    except Exception:
        stats = stats.sort_index()

    return stats

def _export_to_excel(stats_df: pd.DataFrame) -> BytesIO:
    output = BytesIO()
    try:
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            stats_df.to_excel(writer, index=True, sheet_name="Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬", index_label="Î¤ÎœÎ—ÎœÎ‘")
            wb = writer.book
            ws = writer.sheets["Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬"]
            header_fmt = wb.add_format({"bold": True, "valign":"vcenter", "text_wrap": True, "border":1})
            for col_idx, value in enumerate(["Î¤ÎœÎ—ÎœÎ‘"] + list(stats_df.columns)):
                ws.write(0, col_idx, value, header_fmt)
            for i in range(0, len(stats_df.columns)+1):
                ws.set_column(i, i, 18)
    except Exception:
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            stats_df.to_excel(writer, index=True, sheet_name="Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬", index_label="Î¤ÎœÎ—ÎœÎ‘")
    output.seek(0)
    return output

# ---------- UI ----------
c1, c2, c3 = st.columns(3)
with c1:
    if st.button("ğŸ“¥ Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Excel", type="primary"):
        st.session_state.show_upload = True
with c2:
    export_clicked = st.button("ğŸ“Š Î•Î¾Î±Î³Ï‰Î³Î® Î Î™ÎÎ‘ÎšÎ‘ Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ©Î", disabled=st.session_state.data is None)
with c3:
    if st.button("ğŸ”„ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·"):
        st.session_state.data = None
        st.session_state.stats_df = None
        st.session_state.show_upload = False
        st.session_state.diagnostics = {}
        st.rerun()

if st.session_state.show_upload:
    st.markdown("### ğŸ“¥ Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Î‘ÏÏ‡ÎµÎ¯Î¿Ï… Excel")
    up = st.file_uploader("Î•Ï€Î¯Î»ÎµÎ¾Îµ Î±ÏÏ‡ÎµÎ¯Î¿ Excel Î¼Îµ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î¼Î±Î¸Î·Ï„ÏÎ½", type=["xlsx","xls"])
    if up:
        try:
            df_raw = pd.read_excel(up)
            df_norm, ren_map = auto_rename_columns(df_raw)
            st.session_state.data = df_norm.copy()

            # Diagnostics
            present = list(df_norm.columns)
            missing = [c for c in REQUIRED_COLS if c not in present]
            st.session_state.diagnostics = {
                "recognized_columns": present,
                "renamed": ren_map,
                "missing_required": missing,
                "classes_found": sorted([str(x) for x in df_norm["Î¤ÎœÎ—ÎœÎ‘"].dropna().unique()]) if "Î¤ÎœÎ—ÎœÎ‘" in df_norm else []
            }

            st.success(f"âœ… Î•Ï€Î¹Ï„Ï…Ï‡Î®Ï‚ Ï†ÏŒÏÏ„Ï‰ÏƒÎ·! Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(df_norm)} Î¼Î±Î¸Î·Ï„Î­Ï‚.")
            with st.expander("ğŸ” Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ· Î±ÏÏ‡ÎµÎ¯Î¿Ï… (ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î±Î½Î±Î³Î½Ï‰ÏÎ¯ÏƒÏ„Î·ÎºÎ±Î½)", expanded=False):
                st.write("Î‘Î½Î±Î³Î½Ï‰ÏÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î®Î»ÎµÏ‚:", present)
                if ren_map:
                    st.write("Î‘Ï…Ï„ÏŒÎ¼Î±Ï„ÎµÏ‚ Î¼ÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚:", ren_map)
                if missing:
                    st.error("âŒ Î›ÎµÎ¯Ï€Î¿Ï…Î½ Ï…Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚: " + ", ".join(missing))
                if "Î¤ÎœÎ—ÎœÎ‘" in df_norm:
                    st.write("Î¤Î¼Î®Î¼Î±Ï„Î± Ï€Î¿Ï… Î²ÏÎ­Î¸Î·ÎºÎ±Î½:", st.session_state.diagnostics["classes_found"])

            # Live preview stats (Î±Î½ Î´ÎµÎ½ Î»ÎµÎ¯Ï€Î¿Ï…Î½ Ï…Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ­Ï‚)
            if not st.session_state.diagnostics["missing_required"]:
                st.markdown("### ğŸ‘€ Î ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· Î Î¯Î½Î±ÎºÎ± Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½")
                preview = _generate_stats(df_norm)
                st.session_state.stats_df = preview
                st.dataframe(preview, use_container_width=True)
            else:
                st.info("Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ/Î´Î¹ÏŒÏÎ¸Ï‰ÏƒÎµ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î»ÎµÎ¯Ï€Î¿Ï…Î½ ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†ÏŒÏÏ„Ï‰ÏƒÎµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿.")

        except Exception as e:
            st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·: {e}")

# Export
if export_clicked and st.session_state.data is not None:
    if st.session_state.diagnostics and st.session_state.diagnostics.get("missing_required"):
        st.error("Î”ÎµÎ½ Î³Î¯Î½ÎµÏ„Î±Î¹ ÎµÎ¾Î±Î³Ï‰Î³Î®: Î»ÎµÎ¯Ï€Î¿Ï…Î½ Ï…Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚: " + ", ".join(st.session_state.diagnostics["missing_required"]))
    else:
        st.markdown("### ğŸ“Š Î Î¯Î½Î±ÎºÎ±Ï‚ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½")
        stats_df = _generate_stats(st.session_state.data)
        st.session_state.stats_df = stats_df
        st.dataframe(stats_df, use_container_width=True)
        output = _export_to_excel(stats_df)
        st.download_button(
            label="ğŸ’¾ Î›Î®ÏˆÎ· Î Î¯Î½Î±ÎºÎ± Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ (Excel)",
            data=output.getvalue(),
            file_name=f"statistika_mathiton_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )

# Sidebar tips
st.sidebar.markdown("### ğŸ§­ ÎŸÎ´Î·Î³Î¯ÎµÏ‚")
st.sidebar.markdown(
    "- Î Î±Ï„Î®ÏƒÏ„Îµ **Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Excel** ÎºÎ±Î¹ Ï†Î¿ÏÏ„ÏÏƒÏ„Îµ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.\n"
    "- Î‘Î½ Î±Î½Î±Î³Î½Ï‰ÏÎ¹ÏƒÏ„Î¿ÏÎ½ ÏŒÎ»ÎµÏ‚ Î¿Î¹ ÏƒÏ„Î®Î»ÎµÏ‚, Î¸Î± Î´ÎµÎ¯Ï„Îµ **Ï€ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·** Ï„Î¿Ï… Ï€Î¯Î½Î±ÎºÎ±.\n"
    "- Î Î±Ï„Î®ÏƒÏ„Îµ **Î•Î¾Î±Î³Ï‰Î³Î® Î Î™ÎÎ‘ÎšÎ‘ Î£Î¤Î‘Î¤Î™Î£Î¤Î™ÎšÎ©Î** Î³Î¹Î± Î»Î®ÏˆÎ· Ï„Î¿Ï… Excel.\n"
    "- Î‘Ï€Î¿Î´ÎµÎºÏ„Î­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ (ÎµÏ…Î­Î»Î¹ÎºÏ„Î· Î³ÏÎ±Ï†Î®): ÎŸÎÎŸÎœÎ‘, Î¦Î¥Î›ÎŸ (Î‘/Îš), Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥, Î–Î©Î—Î¡ÎŸÎ£, Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘, "
    "ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î (Î® Î“ÎÎ©Î£Î— Î•Î›Î›Î—ÎÎ™ÎšÎ©Î), Î¦Î™Î›ÎŸÎ™/Î¦Î™Î›Î™Î‘, Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—, Î¤ÎœÎ—ÎœÎ‘."
)
